{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3種模型 vgg16 , resnet50, densenet121\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input as preprocess_input_vgg\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input as preprocess_input_resnet\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.applications.densenet import preprocess_input as preprocess_input_densenet\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.applications.inception_resnet_v2 import preprocess_input as preprocess_input_inceptionresnetv2\n",
    "\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import os\n",
    "import h5py\n",
    "# model = VGG16(weights='imagenet', include_top=False)\n",
    "# img_path = './images2/089037468.jpg'\n",
    "# img = image.load_img(img_path, target_size=(224, 224))\n",
    "# x = image.img_to_array(img)\n",
    "# x = np.expand_dims(x, axis=0)\n",
    "# x = preprocess_input(x)\n",
    "# features = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGNet:\n",
    "    def __init__ (self):\n",
    "        self.input_shape = (224,224,3)\n",
    "        self.weight = 'imagenet'\n",
    "        self.pooling = 'max'\n",
    "        # VGG16\n",
    "        self.model_vgg = VGG16(weights=self.weight,\n",
    "                              input_shape = (self.input_shape[0],self.input_shape[1], self.input_shape[2]),\n",
    "                              pooling = self.pooling, include_top = False)\n",
    "        self.model_vgg.predict(np.zeros((1,224,224,3)))\n",
    "        \n",
    "        # ResNet50\n",
    "        self.model_resnet = ResNet50(weights = self.weight, \n",
    "                                     input_shape = (self.input_shape[0], self.input_shape[1], self.input_shape[2]),\n",
    "                                     pooling = self.pooling, include_top = False)\n",
    "        self.model_resnet.predict(np.zeros((1, 224, 224, 3)))\n",
    "        \n",
    "        # DenseNet121\n",
    "        self.model_densenet = DenseNet121(weights = self.weight, \n",
    "                                          input_shape = (self.input_shape[0], self.input_shape[1], self.input_shape[2]), \n",
    "                                          pooling = self.pooling, include_top = False)\n",
    "        self.model_densenet.predict(np.zeros((1, 224, 224, 3)))\n",
    "        \n",
    "#         keras.applications.inception_resnet_v2.InceptionResNetV2(include_top=True, weights='imagenet',\n",
    "#                                                                  input_tensor=None, input_shape=None, \n",
    "#                                                                  pooling=None, classes=1000)\n",
    "        # DenseNet121\n",
    "        self.model_inceptionresnetv2 = InceptionResNetV2(weights = self.weight, \n",
    "                                          input_shape = (self.input_shape[0], self.input_shape[1], self.input_shape[2]), \n",
    "                                          pooling = self.pooling, include_top = False)\n",
    "        self.model_inceptionresnetv2.predict(np.zeros((1, 224, 224, 3)))\n",
    "        \n",
    "    # 提取VGG16最後一層conz特徵\n",
    "    def vgg_extract_feat(self, img_path):\n",
    "        img = image.load_img(img_path, target_size=(self.input_shape[0], self.input_shape[1]))\n",
    "        img = image.img_to_array(img)\n",
    "        img = np.expand_dims(img,axis=0)\n",
    "        img = preprocess_input_vgg(img)\n",
    "        feat = self.model_vgg.predict(img)\n",
    "        norm_feat = feat[0] / LA.norm(feat[0])\n",
    "        return norm_feat\n",
    "    \n",
    "     #提取resnet50最後一層卷積特徵\n",
    "    def resnet_extract_feat(self, img_path):\n",
    "        img = image.load_img(img_path, target_size=(self.input_shape[0], self.input_shape[1]))\n",
    "        img = image.img_to_array(img)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        img = preprocess_input_resnet(img)\n",
    "        feat = self.model_resnet.predict(img)\n",
    "        # print(feat.shape)\n",
    "        norm_feat = feat[0]/LA.norm(feat[0])\n",
    "        return norm_feat\n",
    "    \n",
    "    #提取densenet121最後一層卷積特徵\n",
    "    def densenet_extract_feat(self, img_path):\n",
    "        img = image.load_img(img_path, target_size=(self.input_shape[0], self.input_shape[1]))\n",
    "        img = image.img_to_array(img)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        img = preprocess_input_densenet(img)\n",
    "        feat = self.model_densenet.predict(img)\n",
    "        # print(feat.shape)\n",
    "        norm_feat = feat[0]/LA.norm(feat[0])\n",
    "        return norm_feat\n",
    "        #提取densenet121最後一層卷積特徵\n",
    "    def inceptionresnetv2_extract_feat(self, img_path):\n",
    "        img = image.load_img(img_path, target_size=(self.input_shape[0], self.input_shape[1]))\n",
    "        img = image.img_to_array(img)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        img = preprocess_input_densenet(img)\n",
    "        feat = self.model_densenet.predict(img)\n",
    "        # print(feat.shape)\n",
    "        norm_feat = feat[0]/LA.norm(feat[0])\n",
    "        return norm_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imlist(path):\n",
    "    return [os.path.join(path, f) for f in os.listdir(path) if f.endswith('.jpg')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "               feature extraction starts \n",
      "--------------------------------------------------\n",
      "extracting featurn from image NO. 1 , 106 images in total\n",
      "extracting featurn from image NO. 2 , 106 images in total\n",
      "extracting featurn from image NO. 3 , 106 images in total\n",
      "extracting featurn from image NO. 4 , 106 images in total\n",
      "extracting featurn from image NO. 5 , 106 images in total\n",
      "extracting featurn from image NO. 6 , 106 images in total\n",
      "extracting featurn from image NO. 7 , 106 images in total\n",
      "extracting featurn from image NO. 8 , 106 images in total\n",
      "extracting featurn from image NO. 9 , 106 images in total\n",
      "extracting featurn from image NO. 10 , 106 images in total\n",
      "extracting featurn from image NO. 11 , 106 images in total\n",
      "extracting featurn from image NO. 12 , 106 images in total\n",
      "extracting featurn from image NO. 13 , 106 images in total\n",
      "extracting featurn from image NO. 14 , 106 images in total\n",
      "extracting featurn from image NO. 15 , 106 images in total\n",
      "extracting featurn from image NO. 16 , 106 images in total\n",
      "extracting featurn from image NO. 17 , 106 images in total\n",
      "extracting featurn from image NO. 18 , 106 images in total\n",
      "extracting featurn from image NO. 19 , 106 images in total\n",
      "extracting featurn from image NO. 20 , 106 images in total\n",
      "extracting featurn from image NO. 21 , 106 images in total\n",
      "extracting featurn from image NO. 22 , 106 images in total\n",
      "extracting featurn from image NO. 23 , 106 images in total\n",
      "extracting featurn from image NO. 24 , 106 images in total\n",
      "extracting featurn from image NO. 25 , 106 images in total\n",
      "extracting featurn from image NO. 26 , 106 images in total\n",
      "extracting featurn from image NO. 27 , 106 images in total\n",
      "extracting featurn from image NO. 28 , 106 images in total\n",
      "extracting featurn from image NO. 29 , 106 images in total\n",
      "extracting featurn from image NO. 30 , 106 images in total\n",
      "extracting featurn from image NO. 31 , 106 images in total\n",
      "extracting featurn from image NO. 32 , 106 images in total\n",
      "extracting featurn from image NO. 33 , 106 images in total\n",
      "extracting featurn from image NO. 34 , 106 images in total\n",
      "extracting featurn from image NO. 35 , 106 images in total\n",
      "extracting featurn from image NO. 36 , 106 images in total\n",
      "extracting featurn from image NO. 37 , 106 images in total\n",
      "extracting featurn from image NO. 38 , 106 images in total\n",
      "extracting featurn from image NO. 39 , 106 images in total\n",
      "extracting featurn from image NO. 40 , 106 images in total\n",
      "extracting featurn from image NO. 41 , 106 images in total\n",
      "extracting featurn from image NO. 42 , 106 images in total\n",
      "extracting featurn from image NO. 43 , 106 images in total\n",
      "extracting featurn from image NO. 44 , 106 images in total\n",
      "extracting featurn from image NO. 45 , 106 images in total\n",
      "extracting featurn from image NO. 46 , 106 images in total\n",
      "extracting featurn from image NO. 47 , 106 images in total\n",
      "extracting featurn from image NO. 48 , 106 images in total\n",
      "extracting featurn from image NO. 49 , 106 images in total\n",
      "extracting featurn from image NO. 50 , 106 images in total\n",
      "extracting featurn from image NO. 51 , 106 images in total\n",
      "extracting featurn from image NO. 52 , 106 images in total\n",
      "extracting featurn from image NO. 53 , 106 images in total\n",
      "extracting featurn from image NO. 54 , 106 images in total\n",
      "extracting featurn from image NO. 55 , 106 images in total\n",
      "extracting featurn from image NO. 56 , 106 images in total\n",
      "extracting featurn from image NO. 57 , 106 images in total\n",
      "extracting featurn from image NO. 58 , 106 images in total\n",
      "extracting featurn from image NO. 59 , 106 images in total\n",
      "extracting featurn from image NO. 60 , 106 images in total\n",
      "extracting featurn from image NO. 61 , 106 images in total\n",
      "extracting featurn from image NO. 62 , 106 images in total\n",
      "extracting featurn from image NO. 63 , 106 images in total\n",
      "extracting featurn from image NO. 64 , 106 images in total\n",
      "extracting featurn from image NO. 65 , 106 images in total\n",
      "extracting featurn from image NO. 66 , 106 images in total\n",
      "extracting featurn from image NO. 67 , 106 images in total\n",
      "extracting featurn from image NO. 68 , 106 images in total\n",
      "extracting featurn from image NO. 69 , 106 images in total\n",
      "extracting featurn from image NO. 70 , 106 images in total\n",
      "extracting featurn from image NO. 71 , 106 images in total\n",
      "extracting featurn from image NO. 72 , 106 images in total\n",
      "extracting featurn from image NO. 73 , 106 images in total\n",
      "extracting featurn from image NO. 74 , 106 images in total\n",
      "extracting featurn from image NO. 75 , 106 images in total\n",
      "extracting featurn from image NO. 76 , 106 images in total\n",
      "extracting featurn from image NO. 77 , 106 images in total\n",
      "extracting featurn from image NO. 78 , 106 images in total\n",
      "extracting featurn from image NO. 79 , 106 images in total\n",
      "extracting featurn from image NO. 80 , 106 images in total\n",
      "extracting featurn from image NO. 81 , 106 images in total\n",
      "extracting featurn from image NO. 82 , 106 images in total\n",
      "extracting featurn from image NO. 83 , 106 images in total\n",
      "extracting featurn from image NO. 84 , 106 images in total\n",
      "extracting featurn from image NO. 85 , 106 images in total\n",
      "extracting featurn from image NO. 86 , 106 images in total\n",
      "extracting featurn from image NO. 87 , 106 images in total\n",
      "extracting featurn from image NO. 88 , 106 images in total\n",
      "extracting featurn from image NO. 89 , 106 images in total\n",
      "extracting featurn from image NO. 90 , 106 images in total\n",
      "extracting featurn from image NO. 91 , 106 images in total\n",
      "extracting featurn from image NO. 92 , 106 images in total\n",
      "extracting featurn from image NO. 93 , 106 images in total\n",
      "extracting featurn from image NO. 94 , 106 images in total\n",
      "extracting featurn from image NO. 95 , 106 images in total\n",
      "extracting featurn from image NO. 96 , 106 images in total\n",
      "extracting featurn from image NO. 97 , 106 images in total\n",
      "extracting featurn from image NO. 98 , 106 images in total\n",
      "extracting featurn from image NO. 99 , 106 images in total\n",
      "extracting featurn from image NO. 100 , 106 images in total\n",
      "extracting featurn from image NO. 101 , 106 images in total\n",
      "extracting featurn from image NO. 102 , 106 images in total\n",
      "extracting featurn from image NO. 103 , 106 images in total\n",
      "extracting featurn from image NO. 104 , 106 images in total\n",
      "extracting featurn from image NO. 105 , 106 images in total\n",
      "extracting featurn from image NO. 106 , 106 images in total\n",
      "--------------------------------------------------\n",
      "               writing feature extraction results\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'File' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-9b9afdc32343>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"post_h5f\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'File' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    database = 'images2'\n",
    "    index = 'models/vgg_featureCNN.h5'\n",
    "    img_list = get_imlist(database)\n",
    "    \n",
    "\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"               feature extraction starts \")\n",
    "    print(\"--------------------------------------------------\")\n",
    "    \n",
    "    \n",
    "    feats = []\n",
    "    names = []\n",
    "    \n",
    "    model = VGGNet()\n",
    "    for i, img_path in enumerate(img_list): #修改此處改變提取特徵的網路\n",
    "        \n",
    "        # VGG16\n",
    "#         norm_feat = model.vgg_extract_feat(img_path)\n",
    "        \n",
    "        # ResNet50\n",
    "#         norm_feat = model.resnet_extract_feat(img_path)\n",
    "        \n",
    "        # DenseNet121\n",
    "        norm_feat = model.densenet_extract_feat(img_path)\n",
    "        # inceptionresnetv\n",
    "        norm_feat = model.inceptionresnetv2_extract_feat(img_path)\n",
    "        \n",
    "        \n",
    "        img_name = os.path.split(img_path)[1]\n",
    "        feats.append(norm_feat)\n",
    "        names.append(img_name)\n",
    "        print('extracting featurn from image NO. %d , %d images in total' %((i + 1),len(img_list)))\n",
    "        \n",
    "    feats = np.array(feats)\n",
    "    output = index\n",
    "    \n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"               writing feature extraction results\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "    \n",
    "    h5f = h5py.File(output, 'w')\n",
    "    h5f.create_dataset('dataset_1',data = feats)\n",
    "    h5f.create_dataset('dataset_2',data = np.string_(names))\n",
    "    \n",
    "    h5f.close()\n",
    "    model.save(\"post_h5f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  test.py\n",
    "# -*- coding: utf-8 -*-\n",
    "# from extract_cnn_vgg16_keras import VGGNet\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "# import argparse\n",
    "\n",
    "query = './database/089037524.jpg'\n",
    "index = 'models/vgg_featureCNN.h5'\n",
    "result = 'images2'\n",
    "# read in indexed images' feature vectors and corresponding image names\n",
    "h5f = h5py.File(index,'r')\n",
    "# feats = h5f['dataset_1'][:]\n",
    "feats = h5f['dataset_1'][:]\n",
    "print(feats)\n",
    "imgNames = h5f['dataset_2'][:]\n",
    "print(imgNames)\n",
    "h5f.close()\n",
    "        \n",
    "print(\"--------------------------------------------------\")\n",
    "print(\"               searching starts\")\n",
    "print(\"--------------------------------------------------\")\n",
    "    \n",
    "# read and show query image\n",
    "# queryDir = args[\"query\"]\n",
    "queryImg = mpimg.imread(query)\n",
    "plt.title(\"Query Image\")\n",
    "plt.imshow(queryImg)\n",
    "plt.show()\n",
    "\n",
    "# init VGGNet16 model\n",
    "model = VGGNet()\n",
    "\n",
    "# extract query image's feature, compute simlarity score and sort #修改此處改變提取特徵的網路\n",
    "\n",
    "# VGG16\n",
    "# queryVec = model.vgg_extract_feat(query)\n",
    "\n",
    "# ResNet50\n",
    "# queryVec = model.resnet_extract_feat(query)\n",
    "\n",
    "# DenseNet121\n",
    "# queryVec = model.densenet_extract_feat(query)\n",
    "\n",
    "# Inceptionresnetv2\n",
    "queryVec = model.inceptionresnetv2_extract_feat(query)\n",
    "\n",
    "# print(queryVec.shape)\n",
    "# print(feats.shape)\n",
    "scores = np.dot(queryVec, feats.T)\n",
    "rank_ID = np.argsort(scores)[::-1]\n",
    "rank_score = scores[rank_ID]\n",
    "# print (rank_ID)\n",
    "print (rank_score)\n",
    "\n",
    "\n",
    "# number of top retrieved images to show\n",
    "maxres = 3          #檢索出三張相似度最高的圖片\n",
    "imlist = []\n",
    "for i,index in enumerate(rank_ID[0:maxres]):\n",
    "    imlist.append(imgNames[index])\n",
    "    # print(type(imgNames[index]))\n",
    "    print(\"image names: \"+str(imgNames[index]) + \" scores: %f\"%rank_score[i])\n",
    "print(\"top %d images in order are: \" %maxres, imlist)\n",
    "# show top #maxres retrieved result one by one\n",
    "for i,im in enumerate(imlist):\n",
    "    image = mpimg.imread(result+\"/\"+str(im, 'utf-8'))\n",
    "    plt.title(\"search output %d\" %(i+1))\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
