{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000000015\n",
      "000000025\n",
      "000000022\n",
      "['https://twtmsearch.tipo.gov.tw/imageLoad.jsp?path=/20160227/000/000/015/pic_000000015_20110105_1.jpg&formatName=jpeg&pathCodeId=282_pic', 'https://twtmsearch.tipo.gov.tw/imageLoad.jsp?path=/20160227/000/000/025/pic_000000025_20110105_1.jpg&formatName=jpeg&pathCodeId=282_pic', 'https://twtmsearch.tipo.gov.tw/imageLoad.jsp?path=/20160227/000/000/022/pic_000000022_20110105_1.jpg&formatName=jpeg&pathCodeId=282_pic']\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#  pre-trained model densenet121\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.applications.densenet import preprocess_input\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import cv2\n",
    "from numpy import linalg as LA\n",
    "import h5py\n",
    "from skimage import io\n",
    "import pymongo\n",
    "\n",
    "\n",
    "# 圖片預處理\n",
    "def preprocess_image(image):\n",
    "    try:\n",
    "        # load to gray image\n",
    "        image = cv2.imread(image)\n",
    "        ori = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        gray = cv2.cvtColor(ori, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # 用Sobel算子計算x，y方向上的梯度，之後在x方向上減去y方向上的梯度\n",
    "        # 我們留下具有高水平梯度和低垂直梯度的圖像區域\n",
    "        gradX = cv2.Sobel(gray, ddepth=cv2.CV_32F, dx=1, dy=0, ksize=-1)\n",
    "        gradY = cv2.Sobel(gray, ddepth=cv2.CV_32F, dx=0, dy=1, ksize=-1)\n",
    "        # subtract the y-gradient from the x-gradient\n",
    "        gradient = cv2.subtract(gradX, gradY)\n",
    "        gradient = cv2.convertScaleAbs(gradient)\n",
    "\n",
    "        # blur and the image 去除圖像上的噪聲。\n",
    "        blurred = cv2.blur(gradient, (9, 9))\n",
    "\n",
    "        # threshold the image 對模糊圖像二值化\n",
    "        (_, thresh) = cv2.threshold(blurred, 90, 255, cv2.THRESH_BINARY)\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (25, 25))\n",
    "        closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "        # perform a series of erosions and dilations\n",
    "        closed = cv2.erode(closed, None, iterations=4)  # 侵蝕\n",
    "        closed = cv2.dilate(closed, None, iterations=58)  # 膨脹\n",
    "\n",
    "        # find Contour\n",
    "        (cnts, _) = cv2.findContours(closed.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        c = sorted(cnts, key=cv2.contourArea, reverse=True)[0]\n",
    "\n",
    "        # compute the rotated bounding box of the largest contour\n",
    "        rect = cv2.minAreaRect(c)\n",
    "        box = np.int0(cv2.boxPoints(rect))\n",
    "\n",
    "        # find image bounding box\n",
    "        Xs = [i[0] for i in box]\n",
    "        Ys = [i[1] for i in box]\n",
    "\n",
    "        x1 = min(Xs)\n",
    "        y1 = min(Ys)\n",
    "        x2 = max(Xs)\n",
    "        y2 = max(Ys)\n",
    "\n",
    "        if x1 < 0:\n",
    "            x1 = 0\n",
    "        if y1 < 0:\n",
    "            y1 = 0\n",
    "\n",
    "        hight = y2 - y1\n",
    "        width = x2 - x1\n",
    "        crop_img = image[y1:y1 + hight, x1:x1 + width]\n",
    "\n",
    "        #         img_result = tf.image.resize_with_crop_or_pad(crop_img,590,590)\n",
    "        img_result = tf.image.resize(crop_img, [224, 224])\n",
    "\n",
    "        img_result = np.array(img_result)\n",
    "        img_result = cv2.cvtColor(img_result, cv2.COLOR_BGR2RGB)\n",
    "        return img_result\n",
    "    except IndexError:\n",
    "        print(\"list out of range\")\n",
    "        return -1\n",
    "\n",
    "\n",
    "# run model找出feature\n",
    "def extract_feat(img_path):\n",
    "    # input_shape = (224,224,3)\n",
    "    # img = tf.keras.preprocessing.image.load_img(img_path, target_size=(input_shape[0], input_shape[1]))\n",
    "    # img = keras.preprocessing.image.img_to_array(img)\n",
    "    img = preprocess_image(img_path) # 圖像預處理\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img)\n",
    "    model_densenet = DenseNet121(weights ='imagenet',\n",
    "                            input_shape = (224,224,3),\n",
    "                            pooling = 'max', include_top = False)\n",
    "    feat = model_densenet.predict(img)\n",
    "    norm_feat = feat[0]/LA.norm(feat[0])\n",
    "    return norm_feat\n",
    "\n",
    "# Output imageUrl\n",
    "def find_imgUrl(classNo, img_input):\n",
    "    model_h5 = 'models/feature_%s.h5' % classNo   # feat.h5 檔案路徑\n",
    "    h5f = h5py.File(model_h5, 'r')\n",
    "    feats = h5f['dataset_1'][:]\n",
    "    imgNames = h5f['dataset_2'][:]\n",
    "\n",
    "    feat = extract_feat(img_input)\n",
    "    scores = np.dot(feat, feats.T)\n",
    "    rank_ID = np.argsort(scores)[::-1]\n",
    "\n",
    "    imlist = []\n",
    "    maxres = 3  # output 數量\n",
    "    for i, score in enumerate(rank_ID[0:maxres]):\n",
    "        imgid = str(imgNames[score], 'utf-8').split(\"_\")[1] # 照片名稱 EX:\"001_000000015\" 取後段 imgId\n",
    "        # print(imgid)\n",
    "        imlist.append(imgid)\n",
    "    myclient = pymongo.MongoClient('localhost', 27017)   # MongoDB (ip,27017)\n",
    "    mydb = myclient.test  # dbName\n",
    "    mycol = mydb.tmark_json  # collectionName\n",
    "    results = mycol.find({})\n",
    "    Urllist = []\n",
    "    for result in results:\n",
    "        if result[\"_id\"] in imlist: # key\n",
    "            imgurl = result[\"image\"]\n",
    "            Urllist.append(imgurl)\n",
    "            # print(imgurl)\n",
    "    return Urllist\n",
    "# Output image\n",
    "def find_img(classNo, img_input):\n",
    "    model_h5 = 'models/feature_%s.h5' % classNo\n",
    "    h5f = h5py.File(model_h5, 'r')\n",
    "    feats = h5f['dataset_1'][:]\n",
    "    imgNames = h5f['dataset_2'][:]\n",
    "\n",
    "    feat = extract_feat(img_input)\n",
    "    scores = np.dot(feat, feats.T)\n",
    "    rank_ID = np.argsort(scores)[::-1]\n",
    "\n",
    "    imlist = []\n",
    "    maxres = 3  # output 數量\n",
    "    for i, score in enumerate(rank_ID[0:maxres]):\n",
    "        imgid = str(imgNames[score], 'utf-8').split(\"_\")[1]\n",
    "        # print(imgid)\n",
    "        imlist.append(imgid)\n",
    "    myclient = pymongo.MongoClient('localhost', 27017)\n",
    "    mydb = myclient.test\n",
    "    mycol = mydb.tmark_json\n",
    "    results = mycol.find({})\n",
    "    for result in results:\n",
    "        if result[\"_id\"] in imlist:\n",
    "            image = io.imread(result[\"image\"])\n",
    "            io.imshow(image)\n",
    "            io.show()\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    print(find_imgUrl('012','./database/089037461.jpg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
